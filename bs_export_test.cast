{"version": 2, "width": 157, "height": 47, "timestamp": 1729656152, "idle_time_limit": 5.0, "env": {"SHELL": "/bin/bash", "TERM": "xterm-256color"}, "title": "Batch Size Export Test"}
[0.389446, "o", "\u001b[?2004h(base) \u001b]0;xidaren2@Shark22: ~/xshortfin\u0007\u001b[01;32mxidaren2@Shark22\u001b[00m:\u001b[01;34m~/xshortfin\u001b[00m$ "]
[0.843879, "o", "c"]
[0.899452, "o", "o"]
[0.95785, "o", "n"]
[1.031456, "o", "d"]
[1.14449, "o", "a"]
[1.260011, "o", " "]
[1.391549, "o", "a"]
[1.589749, "o", "c"]
[1.754792, "o", "t"]
[1.858278, "o", "i"]
[1.989978, "o", "v"]
[2.078411, "o", "a"]
[2.215098, "o", "t"]
[2.327102, "o", "e"]
[2.444852, "o", " "]
[2.607855, "o", "e"]
[2.704669, "o", "n"]
[2.811238, "o", "v"]
[3.014732, "o", "1"]
[3.2272, "o", "\r\n\u001b[?2004l\r"]
[3.411918, "o", "b"]
[3.413136, "o", "\u001b[?2004h(env1) \u001b]0;xidaren2@Shark22: ~/xshortfin\u0007\u001b[01;32mxidaren2@Shark22\u001b[00m:\u001b[01;34m~/xshortfin\u001b[00m$ b"]
[3.538011, "o", "a"]
[3.703939, "o", "s"]
[3.817322, "o", "h"]
[3.899385, "o", " "]
[4.071275, "o", "r"]
[4.135337, "o", "e"]
[4.256747, "o", "p"]
[4.453349, "o", "l"]
[4.502125, "o", "i"]
[4.72672, "o", "cate_bsweird.sh "]
[5.247128, "o", "\r\n\u001b[?2004l\r"]
[5.251785, "o", "Starting batch size tests...\r\n\u001b[0;32mTest 1: Single batch size = 1\u001b[0m\r\n\u001b[0;32mTesting batch sizes: 1\u001b[0m\r\n"]
[5.253469, "o", "Exporting model with batch sizes: 1\r\n"]
[7.271936, "o", "/home/xidaren2/SHARK-Platform/sharktank/sharktank/types/gguf_interop/base.py:84: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\r\n  data_tensor = torch.as_tensor(data.reshape(logical_shape))\r\n"]
[7.337107, "o", "Exporting prefill_bs1\r\n"]
[22.232784, "o", "Exporting decode_bs1\r\n"]
[22.270899, "o", "/home/xidaren2/miniforge3/envs/env1/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1364: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:44.)\r\n  empty = torch.empty_strided(\r\n"]
[28.548624, "o", "GENERATED!\r\nExporting\r\n"]
[29.948126, "o", "Saving to '/tmp/sharktank/replicate_weird_decode/model.mlir'\r\n"]
[30.415262, "o", "\u001b[0;32mChecking MLIR output for batch size 1:\u001b[0m\r\nLines containing '_bs':\r\n"]
[30.416977, "o", "  func.func @prefill_bs1(%arg0: !torch.vtensor<[1,?],si64>, %arg1: !torch.vtensor<[1],si64>, %arg2: !torch.vtensor<[1,?],si64>, %arg3: !torch.tensor<[1,2048,32,100],f16>, %arg4: !torch.tensor<[1,2048,32,100],f16>, %arg5: !torch.tensor<[1,2048,32,100],f16>, %arg6: !torch.tensor<[1,2048,32,100],f16>, %arg7: !torch.tensor<[1,2048,32,100],f16>, %arg8: !torch.tensor<[1,2048,32,100],f16>, %arg9: !torch.tensor<[1,2048,32,100],f16>, %arg10: !torch.tensor<[1,2048,32,100],f16>, %arg11: !torch.tensor<[1,2048,32,100],f16>, %arg12: !torch.tensor<[1,2048,32,100],f16>, %arg13: !torch.tensor<[1,2048,32,100],f16>, %arg14: !torch.tensor<[1,2048,32,100],f16>, %arg15: !torch.tensor<[1,2048,32,100],f16>, %arg16: !torch.tensor<[1,2048,32,100],f16>, %arg17: !torch.tensor<[1,2048,32,100],f16>, %arg18: !torch.tensor<[1,2048,32,100],f16>, %arg19: !torch.tensor<[1,2048,32,100],f16>, %arg20: !torch.tensor<[1,2048,32,100],f16>, %arg21: !torch.tensor<[1,2048,32,100],f16>, %arg22: !torch.tensor<[1,2048,32,100],f16>, %arg23: !torch.tensor<[1,2048,32,100],f16>, %arg24: !torch.tensor<[1,2048,32,100],f16>, %arg25: !torch.tensor<[1,2048,32,100],f16>, %arg26: !torch.tensor<[1,2048,32,100],f16>, %arg27: !torch.tensor<[1,2048,32,100],f16>, %arg28: !torch.tensor<[1,2048,32,100],f16>, %arg29: !torch.tensor<[1,2048,32,100],f16>, %arg30: !torch.tensor<[1,2048,32,100],f16>, %arg31: !torch.tensor<[1,2048,32,100],f16>, %arg32: !torch.tensor<[1,2048,32,100],f16>, %arg33: !torch.tensor<[1,2048,32,100],f16>, %arg34: !torch.tensor<[1,2048,32,100],f16>, %arg35: !torch.tensor<[1,2048,32,100],f16>, %arg36: !torch.tensor<[1,2048,32,100],f16>, %arg37: !torch.tensor<[1,2048,32,100],f16>, %arg38: !torch.tensor<[1,2048,32,100],f16>, %arg39: !torch.tensor<[1,2048,32,100],f16>, %arg40: !torch.tensor<[1,2048,32,100],f16>, %arg41: !torch.tensor<[1,2048,32,100],f16>, %arg42: !torch.tensor<[1,2048,32,100],f16>, %arg43: !torch.tensor<[1,2048,32,100],f16>, %arg44: !torch.tensor<[1,2048,32,100],f16>, %arg45: !torch.tensor<[1,2048,32,100],f16>, %arg46: !torch.tensor<[1,2048,32,100],f16>, %arg47: !torch.tensor<[1,2048,32,100],f16>, %arg48: !torch.tensor<[1,2048,32,100],f16>, %arg49: !torch.tensor<[1,2048,32,100],f16>, %arg50: !torch.tensor<[1,2048,32,100],f16>, %arg51: !torch.tensor<[1,2048,32,100],f16>, %arg52: !torch.tensor<[1,2048,32,100],f16>, %arg53: !torch.tensor<[1,2048,32,100],f16>, %arg54: !torch.tensor<[1,2048,32,100],f16>) -> !torch.vtensor<[1,?,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[30.417584, "o", "  func.func @decode_bs1(%arg0: !torch.vtensor<[1,1],si64>, %arg1: !torch.vtensor<[1],si64>, %arg2: !torch.vtensor<[1],si64>, %arg3: !torch.vtensor<[1,?],si64>, %arg4: !torch.vtensor<[1,2048,32,100],f16>, %arg5: !torch.vtensor<[1,2048,32,100],f16>, %arg6: !torch.vtensor<[1,2048,32,100],f16>, %arg7: !torch.vtensor<[1,2048,32,100],f16>, %arg8: !torch.vtensor<[1,2048,32,100],f16>, %arg9: !torch.vtensor<[1,2048,32,100],f16>, %arg10: !torch.vtensor<[1,2048,32,100],f16>, %arg11: !torch.vtensor<[1,2048,32,100],f16>, %arg12: !torch.vtensor<[1,2048,32,100],f16>, %arg13: !torch.vtensor<[1,2048,32,100],f16>, %arg14: !torch.vtensor<[1,2048,32,100],f16>, %arg15: !torch.vtensor<[1,2048,32,100],f16>, %arg16: !torch.vtensor<[1,2048,32,100],f16>, %arg17: !torch.vtensor<[1,2048,32,100],f16>, %arg18: !torch.vtensor<[1,2048,32,100],f16>, %arg19: !torch.vtensor<[1,2048,32,100],f16>, %arg20: !torch.vtensor<[1,2048,32,100],f16>, %arg21: !torch.vtensor<[1,2048,32,100],f16>, %arg22: !torch.vtensor<[1,2048,32,100],f16>, %arg23: !torch.vtensor<[1,2048,32,100],f16>, %arg24: !torch.vtensor<[1,2048,32,100],f16>, %arg25: !torch.vtensor<[1,2048,32,100],f16>, %arg26: !torch.vtensor<[1,2048,32,100],f16>, %arg27: !torch.vtensor<[1,2048,32,100],f16>, %arg28: !torch.vtensor<[1,2048,32,100],f16>, %arg29: !torch.vtensor<[1,2048,32,100],f16>, %arg30: !torch.vtensor<[1,2048,32,100],f16>, %arg31: !torch.vtensor<[1,2048,32,100],f16>, %arg32: !torch.vtensor<[1,2048,32,100],f16>, %arg33: !torch.vtensor<[1,2048,32,100],f16>, %arg34: !torch.vtensor<[1,2048,32,100],f16>, %arg35: !torch.vtensor<[1,2048,32,100],f16>, %arg36: !torch.vtensor<[1,2048,32,100],f16>, %arg37: !torch.vtensor<[1,2048,32,100],f16>, %arg38: !torch.vtensor<[1,2048,32,100],f16>, %arg39: !torch.vtensor<[1,2048,32,100],f16>, %arg40: !torch.vtensor<[1,2048,32,100],f16>, %arg41: !torch.vtensor<[1,2048,32,100],f16>, %arg42: !torch.vtensor<[1,2048,32,100],f16>, %arg43: !torch.vtensor<[1,2048,32,100],f16>, %arg44: !torch.vtensor<[1,2048,32,100],f16>, %arg45: !torch.vtensor<[1,2048,32,100],f16>, %arg46: !torch.vtensor<[1,2048,32,100],f16>, %arg47: !torch.vtensor<[1,2048,32,100],f16>, %arg48: !torch.vtensor<[1,2048,32,100],f16>, %arg49: !torch.vtensor<[1,2048,32,100],f16>, %arg50: !torch.vtensor<[1,2048,32,100],f16>, %arg51: !torch.vtensor<[1,2048,32,100],f16>, %arg52: !torch.vtensor<[1,2048,32,100],f16>, %arg53: !torch.vtensor<[1,2048,32,100],f16>, %arg54: !torch.vtensor<[1,2048,32,100],f16>, %arg55: !torch.vtensor<[1,2048,32,100],f16>) -> !torch.vtensor<[1,1,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[30.418131, "o", "----------------------------------------\r\n\u001b[0;32mTest 2: Single batch size = 4\u001b[0m\r\n"]
[30.418199, "o", "\u001b[0;32mTesting batch sizes: 4\u001b[0m\r\n"]
[30.419602, "o", "Exporting model with batch sizes: 4\r\n"]
[32.239568, "o", "/home/xidaren2/SHARK-Platform/sharktank/sharktank/types/gguf_interop/base.py:84: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\r\n  data_tensor = torch.as_tensor(data.reshape(logical_shape))\r\n"]
[32.307927, "o", "Exporting prefill_bs4\r\n"]
[49.427172, "o", "Exporting decode_bs4\r\n"]
[49.457052, "o", "/home/xidaren2/miniforge3/envs/env1/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1364: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:44.)\r\n  empty = torch.empty_strided(\r\n"]
[61.617533, "o", "GENERATED!\r\nExporting\r\n"]
[63.383907, "o", "Saving to '/tmp/sharktank/replicate_weird_decode/model.mlir'\r\n"]
[64.156568, "o", "\u001b[0;32mChecking MLIR output for batch size 4:\u001b[0m\r\nLines containing '_bs':\r\n"]
[64.158546, "o", "  func.func @prefill_bs4(%arg0: !torch.vtensor<[4,?],si64>, %arg1: !torch.vtensor<[4],si64>, %arg2: !torch.vtensor<[4,?],si64>, %arg3: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[4,?,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[64.159288, "o", "  func.func @decode_bs4(%arg0: !torch.vtensor<[4,1],si64>, %arg1: !torch.vtensor<[4],si64>, %arg2: !torch.vtensor<[4],si64>, %arg3: !torch.vtensor<[4,?],si64>, %arg4: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[4,1,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[64.160126, "o", "----------------------------------------\r\n\u001b[0;32mTest 3: Multiple batch sizes = 1,4\u001b[0m\r\n"]
[64.160185, "o", "\u001b[0;32mTesting batch sizes: 1,4\u001b[0m\r\n"]
[64.16165, "o", "Exporting model with batch sizes: 1,4\r\n"]
[65.977539, "o", "/home/xidaren2/SHARK-Platform/sharktank/sharktank/types/gguf_interop/base.py:84: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\r\n  data_tensor = torch.as_tensor(data.reshape(logical_shape))\r\n"]
[66.044304, "o", "Exporting prefill_bs1\r\n"]
[82.412618, "o", "Exporting decode_bs1\r\n"]
[82.441776, "o", "/home/xidaren2/miniforge3/envs/env1/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1364: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at ../aten/src/ATen/EmptyTensor.cpp:44.)\r\n  empty = torch.empty_strided(\r\n"]
[93.763368, "o", "Exporting prefill_bs4\r\n"]
[112.332999, "o", "Exporting decode_bs4\r\n"]
[124.233923, "o", "GENERATED!\r\nExporting\r\n"]
[128.154813, "o", "Saving to '/tmp/sharktank/replicate_weird_decode/model.mlir'\r\n"]
[128.965521, "o", "\u001b[0;32mChecking MLIR output for batch size 1,4:\u001b[0m\r\nLines containing '_bs':\r\n"]
[128.967371, "o", "  func.func @prefill_bs1(%arg0: !torch.vtensor<[1,?],si64>, %arg1: !torch.vtensor<[1],si64>, %arg2: !torch.vtensor<[1,?],si64>, %arg3: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[1,?,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[128.968292, "o", "  func.func @decode_bs1(%arg0: !torch.vtensor<[1,1],si64>, %arg1: !torch.vtensor<[1],si64>, %arg2: !torch.vtensor<[1],si64>, %arg3: !torch.vtensor<[1,?],si64>, %arg4: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[1,1,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[128.969161, "o", "  func.func @prefill_bs4(%arg0: !torch.vtensor<[4,?],si64>, %arg1: !torch.vtensor<[4],si64>, %arg2: !torch.vtensor<[4,?],si64>, %arg3: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[4,?,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[128.969884, "o", "  func.func @decode_bs4(%arg0: !torch.vtensor<[4,1],si64>, %arg1: !torch.vtensor<[4],si64>, %arg2: !torch.vtensor<[4],si64>, %arg3: !torch.vtensor<[4,?],si64>, %arg4: !torch.tensor<[?,2662400],f16>) -> !torch.vtensor<[4,1,32000],f16> attributes {torch.assume_strict_symbolic_shapes} {\r\n"]
[128.970883, "o", "----------------------------------------\r\n"]
[128.970963, "o", "\u001b[0;32mDone with all tests\u001b[0m\r\n"]
[128.971653, "o", "\u001b[?2004h(env1) \u001b]0;xidaren2@Shark22: ~/xshortfin\u0007\u001b[01;32mxidaren2@Shark22\u001b[00m:\u001b[01;34m~/xshortfin\u001b[00m$ "]
[135.399283, "o", "\r\n\u001b[?2004l\r"]
[135.399399, "o", "\u001b[?2004h(env1) \u001b]0;xidaren2@Shark22: ~/xshortfin\u0007\u001b[01;32mxidaren2@Shark22\u001b[00m:\u001b[01;34m~/xshortfin\u001b[00m$ "]
[135.962411, "o", "\u001b[?2004l\r\r\nexit\r\n"]
